
# Phase 5: 배치 처리 (Batch Processing) 개발 계획

> Celery + Redis 기반 일일 순위 자동 크롤링
> Phase 3 순위 추적 체계 위에 배치 처리 레이어 추가

---

## 1. 개요

Phase 3에서 구축한 순위 추적 체계는 **등록 시점의 초기 순위**만 저장합니다.
일일 순위 변동을 기록하려면 매일 모든 활성 추적 항목을 자동으로 크롤링하는 배치 처리가 필요합니다.

### 1.1 해결하는 문제
| 현재 (Phase 3) | Phase 5 적용 후 |
|----------------|----------------|
| 추적 등록 시 1회만 크롤링 | 매일 지정 시각(기본 KST 01:00) 자동 크롤링 |
| 순위 변동 추적 불가 | RankHistory에 일일 순위 누적 |
| 회차(session) 수동 관리 불가 | 25회 노출 기준 자동 회차 전환 |
| 에러 발생 시 알림 없음 | structlog로 에러 집계 로깅 |

### 1.2 핵심 구성요소
- **Celery Worker**: 크롤링 태스크 실행
- **Celery Beat**: 매일 지정 시각(환경변수) 스케줄링
- **Redis**: 메시지 브로커 (기존 세션 스토어와 공유)

---

## 2. 아키텍처

### 2.1 전체 구조

```
┌──────────────┐     ┌───────────┐     ┌──────────────────┐
│  Celery Beat │────>│   Redis   │<────│  Celery Worker   │
│  (스케줄러)   │     │  (브로커)  │     │  (태스크 실행)    │
└──────────────┘     └───────────┘     └──────┬───────────┘
                                              │
                          ┌───────────────────┼───────────────────┐
                          │                   │                   │
                    ┌─────▼─────┐     ┌───────▼──────┐   ┌───────▼──────┐
                    │ Crawler   │     │  Repository  │   │  structlog   │
                    │ (naver.py)│     │  (DB 저장)   │   │  (결과 로깅)  │
                    └───────────┘     └──────────────┘   └──────────────┘
```

### 2.2 코드 공유 전략
- **크롤러**: `app/crawler/naver.py`의 기존 함수 재사용 (`get_place_rank`, `get_blog_rank`, `get_cafe_rank`)
- **모델/레포지토리**: `app/models/tracking/`, `app/repositories/tracking/` 그대로 사용
- **서비스**: `app/services/rank/rank_service.py`의 `_crawl_rank()` 로직 참조
- **설정**: `app/core/config.py`의 Settings 확장

### 2.3 Worker / Beat 분리
| 구성요소 | 역할 | 인스턴스 수 |
|---------|------|-----------|
| Beat | crontab 스케줄에 따라 태스크 발행 | 1개 (반드시) |
| Worker | 큐에서 태스크를 꺼내 실행 | 1개 (초기), 확장 가능 |

---

## 3. 신규 디렉토리 구조

```
app/tasks/
├── __init__.py           # Celery app import
├── celery_app.py         # Celery 인스턴스 설정, Beat 스케줄
├── rank_tasks.py         # 순위 크롤링 태스크
└── utils.py              # 배치 로깅 유틸리티
```

---

## 4. Celery 설정

### 4.1 celery_app.py 주요 설정

```python
from celery import Celery
from celery.schedules import crontab

celery = Celery("announce_go")

celery.conf.update(
    # 브로커 (Redis) - 기존 redis_url 공유, key prefix로 분리
    broker_url=settings.redis_url,
    result_backend=settings.redis_url,
    broker_transport_options={
        "global_keyprefix": "celery:",
    },
    result_backend_transport_options={
        "global_keyprefix": "celery:",
    },

    # 타임존
    timezone="Asia/Seoul",
    enable_utc=True,

    # 직렬화
    task_serializer="json",
    result_serializer="json",
    accept_content=["json"],

    # 태스크 설정
    task_acks_late=True,              # 처리 완료 후 ACK
    worker_prefetch_multiplier=1,     # 한 번에 1개만 가져옴

    # Beat 스케줄 (환경변수로 시간 설정)
    beat_schedule={
        "daily-rank-crawl": {
            "task": "app.tasks.rank_tasks.crawl_all_active_trackings",
            "schedule": crontab(
                hour=settings.CRAWL_SCHEDULE_HOUR,
                minute=settings.CRAWL_SCHEDULE_MINUTE,
            ),
        },
    },
)

celery.autodiscover_tasks(["app.tasks"])
```

### 4.2 브로커 연결
- 기존 Redis 인스턴스를 브로커로 공유 (동일 DB)
- **key prefix**(`celery:`)로 세션 키와 분리
- SSL 설정은 기존 `redis_url` 프로퍼티 그대로 활용

---

## 5. 태스크 설계

### 5.1 태스크 흐름

```
[Beat] ──> crawl_all_active_trackings (메인 태스크)
                │
                ├── DB에서 활성 추적 목록 조회
                │
                ├── 각 추적 항목마다:
                │     └── crawl_single_tracking.delay(tracking_id) (서브태스크)
                │
                └── 완료 후 결과 요약 로깅

[Worker] ──> crawl_single_tracking(tracking_id)
                │
                ├── 크롤링 실행 (rank_type에 따라 분기)
                ├── RankHistory 저장 (session_number 포함)
                ├── 회차 전환 로직 체크
                └── 실패 시 재시도 (최대 2회)
```

### 5.2 메인 태스크: `crawl_all_active_trackings`

```python
@celery.task(bind=True)
def crawl_all_active_trackings(self):
    """
    모든 활성 추적 항목에 대해 서브태스크 발행

    1. DB에서 status=ACTIVE인 모든 RankTracking 조회
    2. 각 tracking_id에 대해 crawl_single_tracking 서브태스크 발행
    3. 완료 후 결과 요약 로깅
    """
```

### 5.3 서브태스크: `crawl_single_tracking`

```python
@celery.task(bind=True, max_retries=2, default_retry_delay=60)
def crawl_single_tracking(self, tracking_id: int):
    """
    개별 추적 항목 크롤링 및 저장

    1. RankTracking 조회
    2. rank_type에 따라 크롤링 실행
    3. RankHistory 저장 (current_session 기준)
    4. 회차 전환 조건 확인 및 처리
    """
```

### 5.4 회차(Session) 관리 규칙

| 조건 | 동작 |
|------|------|
| 현재 회차의 **노출된 기록** 25회 도달 | `current_session += 1`, 새 회차로 기록 |
| 미노출 (rank=null) | 카운트에서 **제외** |
| 회차 전환 판단 시점 | 크롤링 결과 **저장 직후** |

```python
# 회차 전환 로직 (의사코드)
exposed_count = count(
    RankHistory
    .where(tracking_id=tracking.id)
    .where(session_number=tracking.current_session)
    .where(rank IS NOT NULL)
)

if exposed_count >= 25:
    tracking.current_session += 1
    # 새 회차의 첫 번째 기록으로 저장됨
```

### 5.5 동기(sync) vs 비동기(async) 실행

Celery Worker는 기본적으로 **동기 실행 환경**입니다. 기존 크롤러(`app/crawler/naver.py`)는 `async` 함수이므로:

```python
import asyncio

@celery.task(bind=True, max_retries=2, default_retry_delay=60)
def crawl_single_tracking(self, tracking_id: int):
    asyncio.run(_crawl_single_tracking_async(tracking_id))

async def _crawl_single_tracking_async(tracking_id: int):
    """비동기 크롤링 로직 (기존 코드 재사용)"""
    # DB 세션 생성
    # 크롤링 실행 (get_place_rank / get_blog_rank / get_cafe_rank)
    # RankHistory 저장
    # 회차 전환 체크
```

---

## 6. 스케줄링

### 6.1 Celery Beat crontab

```python
beat_schedule = {
    "daily-rank-crawl": {
        "task": "app.tasks.rank_tasks.crawl_all_active_trackings",
        "schedule": crontab(
            hour=settings.CRAWL_SCHEDULE_HOUR,    # 기본값: 1
            minute=settings.CRAWL_SCHEDULE_MINUTE, # 기본값: 0
        ),
    },
}
```

### 6.2 타임존 설정
- `timezone="Asia/Seoul"` + `enable_utc=True`
- 기본값 KST 01:00, 환경변수(`CRAWL_SCHEDULE_HOUR`, `CRAWL_SCHEDULE_MINUTE`)로 변경 가능
- 내부적으로 UTC 변환하여 처리

### 6.3 수동 실행

```bash
# CLI에서 직접 태스크 실행 (테스트/긴급 시)
celery -A app.tasks.celery_app call app.tasks.rank_tasks.crawl_all_active_trackings
```

---

## 7. 에러 처리 전략

### 7.1 실패 격리
- 서브태스크(`crawl_single_tracking`)는 개별 실행
- 1건 실패해도 나머지 항목은 정상 진행
- 메인 태스크는 서브태스크 발행만 담당 (결과 대기 X)

### 7.2 재시도

```python
@celery.task(
    bind=True,
    max_retries=2,           # 최대 2회 재시도
    default_retry_delay=60,  # 60초 후 재시도
    autoretry_for=(Exception,),
    retry_backoff=True,      # 지수 백오프
)
def crawl_single_tracking(self, tracking_id: int):
    ...
```

| 시도 | 대기 시간 | 설명 |
|------|----------|------|
| 1차 실행 | - | 최초 실행 |
| 1차 재시도 | ~60초 | 첫 번째 재시도 |
| 2차 재시도 | ~120초 | 마지막 재시도 |
| 실패 확정 | - | 에러 로깅 |

### 7.3 배치 결과 로깅

structlog를 사용하여 배치 실행 결과를 구조화 로깅합니다.

```python
# app/tasks/utils.py
def log_batch_summary(total: int, success: int, failed: int, failed_items: list, elapsed: float):
    """배치 실행 결과 요약 로깅"""
    logger.info("batch_completed",
        total=total,
        success=success,
        failed=failed,
        failed_items=failed_items,
        elapsed_seconds=elapsed,
    )
```

**로깅 시점**

| 유형 | 시점 | 로그 레벨 | 내용 |
|------|------|----------|------|
| 배치 시작 | 메인 태스크 시작 | INFO | 활성 추적 항목 수 |
| 배치 완료 | 모든 서브태스크 종료 | INFO | 성공/실패 건수 요약 |
| 개별 실패 | 재시도 모두 소진 시 | ERROR | tracking_id, 에러 메시지 |

**로그 출력 예시**
```json
{
  "event": "batch_completed",
  "total": 150,
  "success": 147,
  "failed": 3,
  "failed_items": [42, 87, 123],
  "elapsed_seconds": 750.3
}
```

---

## 8. Docker Compose 변경

### 8.1 신규 서비스 추가

```yaml
services:
  api:
    image: songhae/announce-go-api
    container_name: announce-go-api
    ports:
      - "8000:8000"
    restart: unless-stopped
    environment:
      - PYTHONUNBUFFERED=1
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  celery_worker:
    image: songhae/announce-go-api
    container_name: announce-go-celery-worker
    command: celery -A app.tasks.celery_app worker --loglevel=info --concurrency=1
    restart: unless-stopped
    environment:
      - PYTHONUNBUFFERED=1
    depends_on:
      - api

  celery_beat:
    image: songhae/announce-go-api
    container_name: announce-go-celery-beat
    command: celery -A app.tasks.celery_app beat --loglevel=info
    restart: unless-stopped
    environment:
      - PYTHONUNBUFFERED=1
    depends_on:
      - api
```

### 8.2 서비스 설명

| 서비스 | 역할 | 비고 |
|--------|------|------|
| `celery_worker` | 크롤링 태스크 실행 | `--concurrency=1` (Playwright 리소스 제한) |
| `celery_beat` | 스케줄에 따라 태스크 발행 | 반드시 1개만 실행 |

### 8.3 이미지 공유
- API 서버와 동일한 Docker 이미지 사용
- `command`만 다르게 지정하여 역할 분리
- Playwright 브라우저가 이미지에 포함되어 있어야 함

---

## 9. 설정 변경

### 9.1 신규 환경변수

| 변수명 | 기본값 | 설명 |
|--------|--------|------|
| `CRAWL_SCHEDULE_HOUR` | `1` | 배치 실행 시각 (시, KST) |
| `CRAWL_SCHEDULE_MINUTE` | `0` | 배치 실행 시각 (분) |
| `CRAWL_DELAY_SECONDS` | `2` | 크롤링 간 대기 시간 (초) |
| `CRAWL_BATCH_TIMEOUT` | `3600` | 배치 전체 타임아웃 (초) |

### 9.2 config.py 변경

```python
class Settings(BaseSettings):
    # ... 기존 설정 ...

    # === Crawling Batch ===
    CRAWL_SCHEDULE_HOUR: int = 1
    CRAWL_SCHEDULE_MINUTE: int = 0
    CRAWL_DELAY_SECONDS: int = 2
    CRAWL_BATCH_TIMEOUT: int = 3600
```

---

## 10. 크롤링 고려사항

### 10.1 Rate Limiting
- **크롤링 간 대기**: 항목 간 `CRAWL_DELAY_SECONDS`(기본 2초) 대기
- **네이버 차단 방지**: 랜덤 User-Agent 사용 (기존 `naver.py` 로직)
- **시간대 선택**: 기본 새벽 1시(KST), 환경변수로 변경 가능

```python
# 서브태스크 간 대기
import time
time.sleep(settings.CRAWL_DELAY_SECONDS)
```

### 10.2 브라우저 관리
- Worker 프로세스 내 `BrowserPool` 싱글턴 재사용
- Worker 시작 시 Playwright 브라우저 초기화
- `--concurrency=1`로 동시 실행 제한 (메모리 관리)

```python
# Celery Worker 시작/종료 시그널
from celery.signals import worker_process_init, worker_process_shutdown

@worker_process_init.connect
def init_browser(**kwargs):
    """Worker 시작 시 브라우저 초기화"""
    asyncio.run(BrowserPool.get_browser())

@worker_process_shutdown.connect
def close_browser(**kwargs):
    """Worker 종료 시 브라우저 정리"""
    asyncio.run(BrowserPool.close())
```

### 10.3 예상 소요 시간

| 활성 추적 수 | 크롤링 + 대기 (건당 ~5초) | 총 소요 시간 |
|-------------|--------------------------|------------|
| 50건 | 50 x 5초 | ~4분 |
| 100건 | 100 x 5초 | ~8분 |
| 300건 | 300 x 5초 | ~25분 |

---

## 11. 모니터링 및 운영

### 11.1 CLI 커맨드

```bash
# 수동 배치 실행
celery -A app.tasks.celery_app call app.tasks.rank_tasks.crawl_all_active_trackings

# Worker 상태 확인
celery -A app.tasks.celery_app inspect active

# 큐 상태 확인
celery -A app.tasks.celery_app inspect reserved

# Beat 스케줄 확인
celery -A app.tasks.celery_app inspect scheduled
```

### 11.2 로깅
- structlog 사용 (기존 프로젝트 패턴 유지)
- 크롤링 결과별 구조화 로깅

```python
logger.info("crawl_result",
    tracking_id=tracking_id,
    rank_type=tracking.type,
    keyword=tracking.keyword,
    rank=rank,
    session_number=session_number,
)
```

### 11.3 Flower (선택사항)
- Celery 모니터링 웹 UI
- 초기 구현에서는 제외, 필요 시 추가

```yaml
# docker-compose.yml (선택)
celery_flower:
  image: songhae/announce-go-api
  container_name: announce-go-celery-flower
  command: celery -A app.tasks.celery_app flower --port=5555
  ports:
    - "5555:5555"
```

---

## 12. 구현 순서 및 파일 목록

### 12.1 구현 순서

#### Step 1: 설정 확장
1. `app/core/config.py` - Celery/Crawl 관련 환경변수 추가

#### Step 2: Celery 앱 설정
1. `app/tasks/__init__.py` - 패키지 초기화
2. `app/tasks/celery_app.py` - Celery 인스턴스, Beat 스케줄, Worker 시그널

#### Step 3: 유틸리티
1. `app/tasks/utils.py` - 배치 로깅 유틸리티

#### Step 4: 태스크 구현
1. `app/tasks/rank_tasks.py` - 메인 태스크 + 서브태스크 + 회차 로직

#### Step 5: Docker Compose
1. `docker-compose.yml` - celery_worker, celery_beat 서비스 추가

#### Step 6: 테스트 및 검증
1. 단위 태스크 실행 테스트
2. 회차 전환 로직 검증
3. 에러 발생 시 재시도 확인
4. 배치 결과 로깅 확인
5. Docker 환경 통합 테스트

### 12.2 파일 생성 목록 (신규 4개)

```
app/tasks/
├── __init__.py           # Celery app import
├── celery_app.py         # Celery 인스턴스, Beat 스케줄
├── rank_tasks.py         # 순위 크롤링 태스크
└── utils.py              # 배치 로깅 유틸리티
```

### 12.3 수정 파일 목록 (기존 2개)

| 파일 | 변경 내용 |
|------|----------|
| `app/core/config.py` | `CRAWL_SCHEDULE_HOUR`, `CRAWL_SCHEDULE_MINUTE`, `CRAWL_DELAY_SECONDS`, `CRAWL_BATCH_TIMEOUT` 추가 |
| `docker-compose.yml` | `celery_worker`, `celery_beat` 서비스 추가 |

### 12.4 참고 파일 (기존)

| 파일 | 참고 내용 |
|------|----------|
| `app/crawler/naver.py` | 크롤러 함수 (재사용) |
| `app/crawler/browser_pool.py` | 브라우저 풀 (Worker에서 재사용) |
| `app/services/rank/rank_service.py` | `_crawl_rank()` 로직 참조 |
| `app/repositories/tracking/rank_tracking_repository.py` | `get_all_active_trackings()` 배치 조회 |
| `app/repositories/tracking/rank_history_repository.py` | 히스토리 저장 |
| `app/models/tracking/rank_tracking.py` | RankTracking, RankHistory 모델 |
| `app/core/config.py` | Settings 패턴, Redis 설정 |